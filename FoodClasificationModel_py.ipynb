{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "D5_0Tmhfow3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets,transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "RR0a-LGNpeAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "7rKnsFQ0yxnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n"
      ],
      "metadata": {
        "id": "K2tTOSJBvTEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "# Download\n",
        "url = \"http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\"\n",
        "filename = \"food-101.tar.gz\"\n",
        "\n",
        "if not os.path.exists(\"food-101.tar.gz\"):\n",
        "    print(\"Downloading Food-101...\")\n",
        "    urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "# Extract\n",
        "if not os.path.exists(\"food-101\"):\n",
        "    print(\"Extracting...\")\n",
        "    with tarfile.open(filename, \"r:gz\") as tar:\n",
        "        tar.extractall()\n"
      ],
      "metadata": {
        "id": "AQDyxRXH3BGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "# Clean any broken/partial files\n",
        "!rm -rf food-101 food-101.tar.gz food101_split\n",
        "\n",
        "# Download the dataset again\n",
        "url = \"http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\"\n",
        "filename = \"food-101.tar.gz\"\n",
        "\n",
        "print(\"Downloading Food-101...\")\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "# Extract\n",
        "print(\"Extracting...\")\n",
        "with tarfile.open(filename, \"r:gz\") as tar:\n",
        "    tar.extractall()\n",
        "\n",
        "# Confirm meta files exist\n",
        "assert os.path.exists(\"food-101/meta/train.txt\"), \"train.txt not found!\"\n",
        "assert os.path.exists(\"food-101/meta/test.txt\"), \"test.txt not found!\"\n",
        "print(\"âœ… Dataset is downloaded and extracted properly.\")\n"
      ],
      "metadata": {
        "id": "cMKxPplIiByN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "def copy_images(split):\n",
        "    with open(f\"food-101/meta/{split}.txt\", \"r\") as f:\n",
        "        lines = f.read().splitlines()\n",
        "\n",
        "    for line in tqdm(lines, desc=f\"Copying {split} data\"):\n",
        "        class_name, image_name = line.split(\"/\")\n",
        "        src = f\"food-101/images/{class_name}/{image_name}.jpg\"\n",
        "        dst_dir = f\"food101_split/{split}/{class_name}/\"\n",
        "        dst = os.path.join(dst_dir, f\"{image_name}.jpg\")\n",
        "\n",
        "        os.makedirs(dst_dir, exist_ok=True)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "os.makedirs(\"food101_split\", exist_ok=True)\n",
        "copy_images(\"train\")\n",
        "copy_images(\"test\")\n"
      ],
      "metadata": {
        "id": "tHO5e2AMkovX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms,datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root = '/content/food101_split/train',transform = transform)\n",
        "test_dataset = datasets.ImageFolder(root = '/content/food101_split/test',transform = transform)\n",
        "train_loader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
        "test_loader = DataLoader(test_dataset,batch_size=32,shuffle=False)"
      ],
      "metadata": {
        "id": "AiCkkKJbm0mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "model  = models.efficientnet_b0(pretrained=True)\n",
        "num_classes = len(train_dataset.classes)\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features,num_classes)\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params = model.parameters(),lr = 0.001)\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "XKceJ-GjnTOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "\n",
        "weights = EfficientNet_B0_Weights.DEFAULT\n",
        "model = efficientnet_b0(weights=weights)\n"
      ],
      "metadata": {
        "id": "qvBBvNSItV_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model:nn.Module,dataloader:torch.utils.data.DataLoader):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for images,labels in test_loader:\n",
        "      images,labels = images.to(device),labels.to(device)\n",
        "      model = model.to(device)\n",
        "      preds = model(images).argmax(dim=1)\n",
        "      correct += (labels == preds).sum().item()\n",
        "      total = labels.size(0)\n",
        "\n",
        "  accuracy = correct/total\n",
        "  print(f\"Accuracy: {accuracy: .3f}\")\n",
        "\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "QRiYFnSgyQTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test(model: nn.Module,\n",
        "               previous_accuracy: float,\n",
        "               previous_loss: float,\n",
        "               epoch: int,\n",
        "               train_loader: torch.utils.data.DataLoader,\n",
        "               test_loader: torch.utils.data.DataLoader):\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    losses_count = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss_value = loss(output, labels)\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss_value.item()\n",
        "        losses_count += 1\n",
        "\n",
        "    average_loss_pe = total_loss / losses_count\n",
        "    current_loss = average_loss_pe\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {average_loss_pe:.4f}\")\n",
        "\n",
        "    if current_loss >= previous_loss:\n",
        "        print(\"The model is starting to overfit (loss increasing). Stopping training.\")\n",
        "        return\n",
        "\n",
        "    current_accuracy = evaluate_model(model, test_loader)\n",
        "\n",
        "    if current_accuracy <= previous_accuracy:\n",
        "        print(\"The model is starting to overfit (accuracy dropping). Stopping training.\")\n",
        "        return\n",
        "\n",
        "    if epoch >= 20:\n",
        "        print(\"More than 20 epochs done. Stopping.\")\n",
        "        return\n",
        "\n",
        "    train_test(model, current_accuracy, current_loss, epoch + 1, train_loader, test_loader)\n"
      ],
      "metadata": {
        "id": "G9ll0qR5_c8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "custom_classifier = model.classifier\n",
        "\n",
        "model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
        "\n",
        "model.classifier = custom_classifier\n",
        "\n",
        "model = model.to(device)\n",
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n"
      ],
      "metadata": {
        "id": "HBWwX1nVCnJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if device == 'cuda':\n",
        "  print(\"Cude is available \")\n",
        "else :\n",
        "  print(\"Cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD7gVWiUcIeA",
        "outputId": "cfaf3864-e16f-4c85-e584-9397680a0d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if device == torch.device('cuda'):\n",
        "    print(\"Device is CUDA\")\n",
        "else:\n",
        "    print(\"Device is not CUDA\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyNBmA9zi2Tj",
        "outputId": "74c61833-4d80-4521-a8da-ca81b8bdae68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device is not CUDA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oa5YOCnglYs5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}